{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FilipSagalara/MasterThesis_SNN_frameworks/blob/main/BRAIN2_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST - Spiking neural network with spike timing dependent plasticity\n",
        "\n",
        "The purpose of this work is to demonstrate local learning rules (STDP) whit the MNIST handwritten digit classification problem. The main ideas are taken from the article [Unsupervised learning of digit recognition using spike-timing-dependent plasticity](https://www.frontiersin.org/articles/10.3389/fncom.2015.00099/full), but the experiment was reconstructed with significant changes from the original work."
      ],
      "metadata": {
        "id": "e3VAvFMeAhbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spiking neural network architecture\n",
        "\n",
        "To model neuron dynamics leaky integrate-and-fire model is used. Synapses are modeled by conductance changes, i.e., synapses increase their conductance instantaneously by the synaptic weight when a presynaptic spike arrives at the synapse, otherwise the conductance is decaying exponentially.\n",
        "\n",
        "The network consists of two layers. The first layer is the input layer, containing 28 × 28 neurons (one neuron per image pixel), and the second layer is the processing layer, containing 100 excitatory neurons and 100 inhibitory neurons. Each input is a Poisson spike-train, which is fed to the excitatory neurons of the second layer for the 350 ms following by 150 ms resting period. The rates of each neuron are proportional (devided by 4) to the intensity of the corresponding pixel in the example image.\n",
        "\n",
        "The excitatory neurons of the second layer are connected in a one-to-one fashion to inhibitory neurons, i.e., each spike in an excitatory neuron will trigger a spike in its corresponding inhibitory neuron. Each of the inhibitory neurons is connected to all excitatory ones, except for the one from which it receives a connection. This connectivity provides lateral inhibition and leads to competition among excitatory neurons. All synapses from input neurons to excitatory neurons are learned using STDP. The weights of the remaining synapses are fixed.\n",
        "\n",
        "![image.png](attachment:ad6a31c8-9ff4-4e0c-b688-532c1cb8bb43.png)\n",
        "\n",
        "To understand this part I recomend [https://www.coursera.org/learn/synapses/](https://www.coursera.org/learn/synapses/)"
      ],
      "metadata": {
        "id": "D2I8bgNcAhbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment design and observed results\n",
        "\n",
        "1. Feed train set to SNN described above\n",
        "2. Freeze STDP\n",
        "3. Feed train set to SNN again and collect generated features (spike counts foreach excitatory neuron during single image representation)\n",
        "4. Train RandomForest on the top of these features and labels provided\n",
        "5. Feed test set to SNN and collect new features\n",
        "6. Predict labels with RandomForest and calculate accuacy score\n",
        "\n",
        "It reaches 0.9 accuracy on the test set with only 5k training examples and 3 classes. In order to understand whether local learning affects the result, the experiment was repeated but without training SNN with STDP. Second experiment scored 0.74, which clearly shows the efficiency of local training."
      ],
      "metadata": {
        "id": "0Mw-lB2SAhbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "class Metrics:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.accuracies = []\n",
        "    self.losses = []\n",
        "    self.prec_micros = []\n",
        "    self.rec_micro = []\n",
        "    self.f1_s_micro = []\n",
        "    self.prec_macro = []\n",
        "    self.rec_macro = []\n",
        "    self.f1_s_macro = []\n",
        "    self.prec_weight = []\n",
        "    self.rec_weight = []\n",
        "    self.f1_s_weight = []\n",
        "    self.classifi_report = []\n",
        "    self.confusion_matrices = []\n",
        "    self.times_per_epoch = []\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.accuracies = []\n",
        "    self.losses = []\n",
        "    self.prec_micros = []\n",
        "    self.rec_micro = []\n",
        "    self.f1_s_micro = []\n",
        "    self.prec_macro = []\n",
        "    self.rec_macro = []\n",
        "    self.f1_s_macro = []\n",
        "    self.prec_weight = []\n",
        "    self.rec_weight = []\n",
        "    self.f1_s_weight = []\n",
        "    self.classifi_report = []\n",
        "    self.confusion_matrices = []\n",
        "    self.times_per_epoch = []\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  def my_custom_loss_func(y_true, y_pred):\n",
        "    diff = np.abs(y_true - y_pred).max()\n",
        "    return np.log1p(diff)\n",
        "\n",
        "\n",
        "\n",
        "  def compute_metrics(self, y_pred, y_test, show = False): #y test refers to true labels\n",
        "    target_names = ['0','1','2','3','4','5','6','7','8','9']\n",
        "    #Compute loss\n",
        "    # loss = log_loss(y_test, y_pred, labels = target_names)\n",
        "    loss = my_custom_loss_func(y_test, y_pred)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    prec_micro = precision_score(y_test, y_pred, average='micro')\n",
        "    rec_micro = recall_score(y_test, y_pred, average='micro')\n",
        "    f1_s_micro = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "    prec_macro = precision_score(y_test, y_pred, average='macro')\n",
        "    rec_macro = recall_score(y_test, y_pred, average='macro')\n",
        "    f1_s_macro = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    prec_weight = precision_score(y_test, y_pred, average='weighted')\n",
        "    rec_weight = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1_s_weight = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "    classifi_report = classification_report(y_test, y_pred, target_names=target_names)\n",
        "\n",
        "    # Update metrics\n",
        "    self.accuracies.append(acc)\n",
        "    self.losses.append(loss)\n",
        "    self.prec_micros.append(prec_micro)\n",
        "    self.rec_micro.append(rec_micro)\n",
        "    self.f1_s_micro.append(f1_s_micro)\n",
        "    self.prec_macro.append(prec_macro)\n",
        "    self.rec_macro.append(rec_macro)\n",
        "    self.f1_s_macro.append(f1_s_macro)\n",
        "    self.prec_weight.append(prec_weight)\n",
        "    self.rec_weight.append(rec_weight)\n",
        "    self.f1_s_weight.append(f1_s_weight)\n",
        "\n",
        "    if show:\n",
        "      print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
        "      print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
        "      print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
        "      print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
        "\n",
        "      print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
        "      print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
        "      print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
        "\n",
        "      print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
        "      print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
        "      print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
        "\n",
        "      print('\\nClassification Report\\n')\n",
        "      print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "    return acc, loss, prec_micro, rec_micro, f1_s_micro, prec_macro, rec_macro, f1_s_macro, prec_weight, rec_weight, f1_s_weight, classifi_report\n",
        "\n",
        "  def compute_confusion_matrix(self, y_pred, y_test):\n",
        "    cm = confusion_matrix(y_true=y_test, y_pred = y_pred)\n",
        "    #print(cm)\n",
        "    # cm_display = ConfusionMatrixDisplay(cm).plot()\n",
        "    self.confusion_matrices.append(cm)\n",
        "\n",
        "\n",
        "  def send_to_drive(self, name : str):\n",
        "    if not name:\n",
        "      print(\"Error: Filename is empty\")\n",
        "      return\n",
        "    \n",
        "    df2 = pd.DataFrame(np.array([self.accuracies, self.prec_micros, self.rec_micro, self.f1_s_micro, self.prec_macro, self.rec_macro, self.f1_s_macro, self.prec_weight, self.rec_weight, self.f1_s_weight, self.times_per_epoch]),\n",
        "    columns=['accuracies', 'prec_micros', 'rec_micro', 'f1_s_micro', 'prec_macro', 'rec_macro', 'f1_s_macro', 'prec_weight','rec_weight', 'f1_s_weight', 'times_per_epoch'])\n",
        "    destination = \"/content/drive/My Drive/\" + name + \".xlsx\"\n",
        "    df2.to_excel(destination)\n",
        "    print(\"Saved at: {}\".format(destination))\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "spyketorch_metrics = Metrics()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T23:25:24.293721Z",
          "iopub.execute_input": "2023-05-29T23:25:24.294147Z",
          "iopub.status.idle": "2023-05-29T23:25:24.418865Z",
          "shell.execute_reply.started": "2023-05-29T23:25:24.294112Z",
          "shell.execute_reply": "2023-05-29T23:25:24.417285Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X2E44JGAhbI",
        "outputId": "56ad97eb-11b6-4306-c34a-b7746fac0f54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class Timer:\n",
        "    def __enter__(self):\n",
        "        self.start_time = time.time()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        self.end_time = time.time()\n",
        "        self.execution_time = self.end_time - self.start_time\n",
        "\n",
        "    def get_execution_time(self):\n",
        "        return self.execution_time\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:41:29.067536Z",
          "iopub.execute_input": "2023-05-29T22:41:29.067854Z",
          "iopub.status.idle": "2023-05-29T22:41:29.081985Z",
          "shell.execute_reply.started": "2023-05-29T22:41:29.067781Z",
          "shell.execute_reply": "2023-05-29T22:41:29.080745Z"
        },
        "trusted": true,
        "id": "ZP_58784AhbK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# brian2 is a simulator for spiking neural networks. It allows to simulate neuraldinamics \n",
        "# using custom differential equations, but it is very computationally intensive.\n",
        "# https://brian2.readthedocs.io/en/stable/resources/tutorials/index.html\n",
        "\n",
        "!pip install brian2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:41:29.083531Z",
          "iopub.execute_input": "2023-05-29T22:41:29.084114Z",
          "iopub.status.idle": "2023-05-29T22:41:39.007072Z",
          "shell.execute_reply.started": "2023-05-29T22:41:29.084075Z",
          "shell.execute_reply": "2023-05-29T22:41:39.006016Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_ZKOs2QAhbK",
        "outputId": "157b99d9-1870-4021-a6d4-5d90c1d7cf6e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting brian2\n",
            "  Downloading Brian2-2.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from brian2) (1.22.4)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from brian2) (0.29.34)\n",
            "Requirement already satisfied: sympy>=1.2 in /usr/local/lib/python3.10/dist-packages (from brian2) (1.11.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from brian2) (3.0.9)\n",
            "Requirement already satisfied: jinja2>=2.7 in /usr/local/lib/python3.10/dist-packages (from brian2) (3.1.2)\n",
            "Requirement already satisfied: setuptools>=24.2 in /usr/local/lib/python3.10/dist-packages (from brian2) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.7->brian2) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.2->brian2) (1.3.0)\n",
            "Installing collected packages: brian2\n",
            "Successfully installed brian2-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from brian2 import *\n",
        "import brian2.numpy_ as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-05-29T22:41:39.010222Z",
          "iopub.execute_input": "2023-05-29T22:41:39.010613Z",
          "iopub.status.idle": "2023-05-29T22:41:49.167513Z",
          "shell.execute_reply.started": "2023-05-29T22:41:39.010577Z",
          "shell.execute_reply": "2023-05-29T22:41:49.166391Z"
        },
        "trusted": true,
        "id": "VDO8HToiAhbL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# simplified classification (0 1 and 8)\n",
        "X_train = X_train[(y_train == 1) | (y_train == 0) | (y_train == 8)]\n",
        "y_train = y_train[(y_train == 1) | (y_train == 0) | (y_train == 8)]\n",
        "X_test = X_test[(y_test == 1) | (y_test == 0) | (y_test == 8)]\n",
        "y_test = y_test[(y_test == 1) | (y_test == 0) | (y_test == 8)]\n",
        "\n",
        "# pixel intensity to Hz (255 becoms ~63Hz)\n",
        "X_train = X_train / 4 \n",
        "X_test = X_test / 4\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:41:49.169569Z",
          "iopub.execute_input": "2023-05-29T22:41:49.169931Z",
          "iopub.status.idle": "2023-05-29T22:41:49.650235Z",
          "shell.execute_reply.started": "2023-05-29T22:41:49.169895Z",
          "shell.execute_reply": "2023-05-29T22:41:49.648943Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTaM_EukAhbM",
        "outputId": "dd9740be-6820-4e21-b796-f4e50770616d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((18516, 28, 28), (3089, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(figsize=(16,8))\n",
        "# for img in range(32):\n",
        "#     plt.subplot(4,8,1+img)\n",
        "#     plt.title(y_train[img])\n",
        "#     plt.imshow(X_train[img])\n",
        "#     plt.axis('off')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:41:49.651878Z",
          "iopub.execute_input": "2023-05-29T22:41:49.652266Z",
          "iopub.status.idle": "2023-05-29T22:41:51.328296Z",
          "shell.execute_reply.started": "2023-05-29T22:41:49.652226Z",
          "shell.execute_reply": "2023-05-29T22:41:51.327370Z"
        },
        "trusted": true,
        "id": "4ECoGiTyAhbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = 28*28 # input layer\n",
        "n_e = 100 # e - excitatory\n",
        "n_i = n_e # i - inhibitory\n",
        "\n",
        "v_rest_e = -60.*mV # v - membrane potential\n",
        "v_reset_e = -65.*mV\n",
        "v_thresh_e = -52.*mV\n",
        "\n",
        "v_rest_i = -60.*mV\n",
        "v_reset_i = -45.*mV\n",
        "v_thresh_i = -40.*mV\n",
        "\n",
        "taupre = 20*ms\n",
        "taupost = taupre\n",
        "gmax = .05 #.01\n",
        "dApre = .01\n",
        "dApost = -dApre * taupre / taupost * 1.05\n",
        "dApost *= gmax \n",
        "dApre *= gmax \n",
        "\n",
        "# Apre and Apost - presynaptic and postsynaptic traces, lr - learning rate\n",
        "stdp='''w : 1\n",
        "    lr : 1 (shared)\n",
        "    dApre/dt = -Apre / taupre : 1 (event-driven)\n",
        "    dApost/dt = -Apost / taupost : 1 (event-driven)'''\n",
        "pre='''ge += w\n",
        "    Apre += dApre\n",
        "    w = clip(w + lr*Apost, 0, gmax)'''\n",
        "post='''Apost += dApost\n",
        "    w = clip(w + lr*Apre, 0, gmax)'''\n",
        "\n",
        "class Model():\n",
        "    \n",
        "    def __init__(self, debug=False):\n",
        "        app = {}\n",
        "                \n",
        "        # input images as rate encoded Poisson generators\n",
        "        app['PG'] = PoissonGroup(n_input, rates=np.zeros(n_input)*Hz, name='PG')\n",
        "        \n",
        "        # excitatory group\n",
        "        neuron_e = '''\n",
        "            dv/dt = (ge*(0*mV-v) + gi*(-100*mV-v) + (v_rest_e-v)) / (100*ms) : volt\n",
        "            dge/dt = -ge / (5*ms) : 1\n",
        "            dgi/dt = -gi / (10*ms) : 1\n",
        "            '''\n",
        "        app['EG'] = NeuronGroup(n_e, neuron_e, threshold='v>v_thresh_e', refractory=5*ms, reset='v=v_reset_e', method='euler', name='EG')\n",
        "        app['EG'].v = v_rest_e - 20.*mV\n",
        "        \n",
        "        if (debug):\n",
        "            app['ESP'] = SpikeMonitor(app['EG'], name='ESP')\n",
        "            app['ESM'] = StateMonitor(app['EG'], ['v'], record=True, name='ESM')\n",
        "            app['ERM'] = PopulationRateMonitor(app['EG'], name='ERM')\n",
        "        \n",
        "        # ibhibitory group\n",
        "        neuron_i = '''\n",
        "            dv/dt = (ge*(0*mV-v) + (v_rest_i-v)) / (10*ms) : volt\n",
        "            dge/dt = -ge / (5*ms) : 1\n",
        "            '''\n",
        "        app['IG'] = NeuronGroup(n_i, neuron_i, threshold='v>v_thresh_i', refractory=2*ms, reset='v=v_reset_i', method='euler', name='IG')\n",
        "        app['IG'].v = v_rest_i - 20.*mV\n",
        "\n",
        "        if (debug):\n",
        "            app['ISP'] = SpikeMonitor(app['IG'], name='ISP')\n",
        "            app['ISM'] = StateMonitor(app['IG'], ['v'], record=True, name='ISM')\n",
        "            app['IRM'] = PopulationRateMonitor(app['IG'], name='IRM')\n",
        "        \n",
        "        # poisson generators one-to-all excitatory neurons with plastic connections \n",
        "        app['S1'] = Synapses(app['PG'], app['EG'], stdp, on_pre=pre, on_post=post, method='euler', name='S1')\n",
        "        app['S1'].connect()\n",
        "        app['S1'].w = 'rand()*gmax' # random weights initialisation\n",
        "        app['S1'].lr = 1 # enable stdp        \n",
        "        \n",
        "        if (debug):\n",
        "            # some synapses\n",
        "            app['S1M'] = StateMonitor(app['S1'], ['w', 'Apre', 'Apost'], record=app['S1'][380,:4], name='S1M') \n",
        "        \n",
        "        # excitatory neurons one-to-one inhibitory neurons\n",
        "        app['S2'] = Synapses(app['EG'], app['IG'], 'w : 1', on_pre='ge += w', name='S2')\n",
        "        app['S2'].connect(j='i')\n",
        "        app['S2'].delay = 'rand()*10*ms'\n",
        "        app['S2'].w = 3 # very strong fixed weights to ensure corresponding inhibitory neuron will always fire\n",
        "\n",
        "        # inhibitory neurons one-to-all-except-one excitatory neurons\n",
        "        app['S3'] = Synapses(app['IG'], app['EG'], 'w : 1', on_pre='gi += w', name='S3')\n",
        "        app['S3'].connect(condition='i!=j')\n",
        "        app['S3'].delay = 'rand()*5*ms'\n",
        "        app['S3'].w = .03 # weights are selected in such a way as to maintain a balance between excitation and ibhibition\n",
        "        \n",
        "        self.net = Network(app.values())\n",
        "        self.net.run(0*second)\n",
        "        \n",
        "    def __getitem__(self, key):\n",
        "        return self.net[key]\n",
        "    \n",
        "    def train(self, X, epoch=1):        \n",
        "        self.net['S1'].lr = 1 # stdp on\n",
        "        \n",
        "        for ep in range(epoch):\n",
        "            for idx in range(len(X)):\n",
        "                # active mode\n",
        "                self.net['PG'].rates = X[idx].ravel()*Hz\n",
        "                self.net.run(0.35*second)\n",
        "\n",
        "                # passive mode\n",
        "                self.net['PG'].rates = np.zeros(n_input)*Hz\n",
        "                self.net.run(0.15*second)\n",
        "        \n",
        "    def evaluate(self, X):       \n",
        "        self.net['S1'].lr = 0  # stdp off\n",
        "        \n",
        "        features = []\n",
        "        for idx in range(len(X)):\n",
        "            # rate monitor to count spikes\n",
        "            mon = SpikeMonitor(self.net['EG'], name='RM')\n",
        "            self.net.add(mon)\n",
        "            \n",
        "            # active mode\n",
        "            self.net['PG'].rates = X[idx].ravel()*Hz\n",
        "            self.net.run(0.35*second)\n",
        "            \n",
        "            # spikes per neuron foreach image\n",
        "            features.append(np.array(mon.count, dtype=int8))\n",
        "            \n",
        "            # passive mode\n",
        "            self.net['PG'].rates = np.zeros(n_input)*Hz\n",
        "            self.net.run(0.15*second)\n",
        "            \n",
        "            self.net.remove(self.net['RM'])\n",
        "            \n",
        "        return features"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:41:51.329817Z",
          "iopub.execute_input": "2023-05-29T22:41:51.330496Z",
          "iopub.status.idle": "2023-05-29T22:41:51.358193Z",
          "shell.execute_reply.started": "2023-05-29T22:41:51.330447Z",
          "shell.execute_reply": "2023-05-29T22:41:51.357308Z"
        },
        "trusted": true,
        "id": "iO_tnPCJAhbN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_w(S1M):\n",
        "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "    subplot(311)\n",
        "    plot(S1M.t/ms, S1M.w.T/gmax)\n",
        "    ylabel('w / wmax')\n",
        "    subplot(312)\n",
        "    plot(S1M.t/ms, S1M.Apre.T)\n",
        "    ylabel('apre')\n",
        "    subplot(313)\n",
        "    plot(S1M.t/ms, S1M.Apost.T)\n",
        "    ylabel('apost')\n",
        "    tight_layout()\n",
        "    show();\n",
        "    \n",
        "def plot_v(ESM, ISM, neuron=13):\n",
        "    plt.rcParams[\"figure.figsize\"] = (20,6)\n",
        "    cnt = -50000 # tail\n",
        "    plot(ESM.t[cnt:]/ms, ESM.v[neuron][cnt:]/mV, label='exc', color='r')\n",
        "    plot(ISM.t[cnt:]/ms, ISM.v[neuron][cnt:]/mV, label='inh', color='b')\n",
        "    plt.axhline(y=v_thresh_e/mV, color='pink', label='v_thresh_e')\n",
        "    plt.axhline(y=v_thresh_i/mV, color='silver', label='v_thresh_i')\n",
        "    legend()\n",
        "    ylabel('v')\n",
        "    show();\n",
        "    \n",
        "def plot_rates(ERM, IRM):\n",
        "    plt.rcParams[\"figure.figsize\"] = (20,6)\n",
        "    plot(ERM.t/ms, ERM.smooth_rate(window='flat', width=0.1*ms)*Hz, color='r')\n",
        "    plot(IRM.t/ms, IRM.smooth_rate(window='flat', width=0.1*ms)*Hz, color='b')\n",
        "    ylabel('Rate')\n",
        "    show();\n",
        "    \n",
        "def plot_spikes(ESP, ISP):\n",
        "    plt.rcParams[\"figure.figsize\"] = (20,6)\n",
        "    plot(ESP.t/ms, ESP.i, '.r')\n",
        "    plot(ISP.t/ms, ISP.i, '.b')\n",
        "    ylabel('Neuron index')\n",
        "    show();\n",
        "\n",
        "def test0(train_items=30):\n",
        "    '''\n",
        "    STDP visualisation\n",
        "    '''\n",
        "    seed(0)\n",
        "    \n",
        "    model = Model(debug=True)\n",
        "    model.train(X_train[:train_items], epoch=1)\n",
        "    \n",
        "    plot_w(model['S1M'])\n",
        "    plot_v(model['ESM'], model['ISM'])\n",
        "    plot_rates(model['ERM'], model['IRM'])\n",
        "    plot_spikes(model['ESP'], model['ISP'])\n",
        "    \n",
        "test0()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:41:51.361480Z",
          "iopub.execute_input": "2023-05-29T22:41:51.361830Z",
          "iopub.status.idle": "2023-05-29T22:44:52.643098Z",
          "shell.execute_reply.started": "2023-05-29T22:41:51.361800Z",
          "shell.execute_reply": "2023-05-29T22:44:52.642223Z"
        },
        "trusted": true,
        "id": "wvb3MapDAhbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test1(train_items=5000, assign_items=1000, eval_items=1000):\n",
        "    '''\n",
        "    Feed train set to SNN with STDP\n",
        "    Freeze STDP\n",
        "    Feed train set to SNN again and collect generated features\n",
        "    Train RandomForest on the top of these features and labels provided\n",
        "    Feed test set to SNN and collect new features\n",
        "    Predict labels with RandomForest and calculate accuacy score\n",
        "    '''\n",
        "    seed(0)\n",
        "    \n",
        "    model = Model()\n",
        "    model.train(X_train[:train_items], epoch=1)\n",
        "    model.net.store('train', 'train.b2')\n",
        "    #model.net.restore('train', './train.b2')\n",
        "    \n",
        "    f_train = model.evaluate(X_train[:assign_items])\n",
        "    clf = RandomForestClassifier(max_depth=4, random_state=0)\n",
        "    clf.fit(f_train, y_train[:assign_items])\n",
        "    print(clf.score(f_train, y_train[:assign_items]))\n",
        "\n",
        "    f_test = model.evaluate(X_test[:eval_items])\n",
        "    y_pred = clf.predict(f_test)\n",
        "    print(accuracy_score(y_pred, y_test[:eval_items]))\n",
        "\n",
        "    cm = confusion_matrix(y_pred, y_test[:eval_items])\n",
        "    print(cm)\n",
        "    \n",
        "test1()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:44:52.653449Z",
          "iopub.status.idle": "2023-05-29T22:44:52.654305Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqnI4IC4AhbQ",
        "outputId": "0f3d4e40-b206-4760-d210-ba1c9c0f3b2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.935\n",
            "0.907\n",
            "[[299   0  35]\n",
            " [  0 368  43]\n",
            " [  5  10 240]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test2(train_items=5000, assign_items=1000, eval_items=1000):\n",
        "    '''\n",
        "    Freeze STDP at start\n",
        "    Feed train set to SNN and collect generated features\n",
        "    Train RandomForest on the top of these features and labels provided\n",
        "    Feed test set to SNN and collect new features\n",
        "    Predict labels with RandomForest and calculate accuacy score\n",
        "    '''\n",
        "    seed(0)\n",
        "    \n",
        "    model = Model()\n",
        "        \n",
        "    f_train = model.evaluate(X_train[:assign_items])\n",
        "    clf = RandomForestClassifier(max_depth=4, random_state=0)\n",
        "    clf.fit(f_train, y_train[:assign_items])\n",
        "    print(clf.score(f_train, y_train[:assign_items]))\n",
        "\n",
        "    f_test = model.evaluate(X_test[:eval_items])\n",
        "    y_pred = clf.predict(f_test)\n",
        "    print(accuracy_score(y_pred, y_test[:eval_items]))\n",
        "\n",
        "    cm = confusion_matrix(y_pred, y_test[:eval_items])\n",
        "    print(cm)\n",
        "    \n",
        "test2()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:44:52.655663Z",
          "iopub.status.idle": "2023-05-29T22:44:52.656579Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_bvZvsPAhbQ",
        "outputId": "0dc5f596-5314-494f-c3fc-b6e024086ee2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.849\n",
            "0.787\n",
            "[[216   2  72]\n",
            " [ 10 359  34]\n",
            " [ 78  17 212]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test3(train_items=5000, eval_items=1000):\n",
        "    '''\n",
        "    Train and evaluate RandomForest without SNN\n",
        "    '''\n",
        "    seed(0)\n",
        "    \n",
        "    clf = RandomForestClassifier(max_depth=4, random_state=0)\n",
        "    \n",
        "    train_features = X_train[:train_items].reshape(-1,28*28)\n",
        "    clf.fit(train_features, y_train[:train_items])\n",
        "    print(clf.score(train_features, y_train[:train_items]))\n",
        "    \n",
        "    test_features = X_test[:eval_items].reshape(-1,28*28)\n",
        "    y_pred = clf.predict(test_features)\n",
        "    print(accuracy_score(y_pred, y_test[:eval_items]))\n",
        "\n",
        "    cm = confusion_matrix(y_pred, y_test[:eval_items])\n",
        "    print(cm)\n",
        "    \n",
        "test3()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-29T22:44:52.657953Z",
          "iopub.status.idle": "2023-05-29T22:44:52.658838Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr6qH6CFAhbQ",
        "outputId": "c366bd4b-0476-4883-c309-52f12b5a509a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.973\n",
            "0.984\n",
            "[[303   0   4]\n",
            " [  0 370   3]\n",
            " [  1   8 311]]\n"
          ]
        }
      ]
    }
  ]
}